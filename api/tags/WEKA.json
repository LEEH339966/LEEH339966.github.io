{"name":"WEKA","slug":"WEKA","count":1,"postlist":[{"title":"WEKA把分类(Classification)和回归(Regression)","slug":"WEKA把分类(Classification)和回归(Regression)","date":"2018-06-17T03:23:39.109Z","updated":"2018-06-17T03:23:19.067Z","comments":true,"path":"api/articles/WEKA把分类(Classification)和回归(Regression).json","excerpt":"","keywords":null,"cover":"http://upload-images.jianshu.io/upload_images/11634944-884f92b05f6e921c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600","content":"<hr>\n<h3 id=\"1-简介\"><a href=\"#1-简介\" class=\"headerlink\" title=\"1 简介\"></a>1 简介</h3><p>WEKA把分类(Classification)和回归(Regression)都放在“Classify”选项卡中，我们希望根据一个样本的一组特征，对目标进行预测。为了实现这一目的， 我们需要有一个训练数据集，这个数据集中每个实例的输入和输出都是已知的。观察训练集中的实例，可以建立起预测的模型。有了这个模型，我们就可以新的输出未知的实例进行预测了，衡量模型的好坏就在于预测的准确程度。 </p>\n<p>在WEKA中，待预测的目标（输出）被称作Class属性，这应该是来自分类任务的“类”。一般的，若Class属性是分类型时我们的任务才叫分类，Class属性是数值型时我们的任务叫回归。</p>\n<p>这里介绍用C4.5决策树算法对数据建立起分类模型，C4.5算法可以处理数值型的属性。</p>\n<p>首先选择数据源，然后切换到“Classify”选项卡，点击“Choose”按钮后可以看到很多分类或者回归的算法分门别类在一个树型框里。 树型框下方有一个“Filter…”按钮，点击可以根据数据集的特性过滤掉不合适的算法。选择“trees”下的“J48”，这就是需要的C4.5算法。 </p>\n<h3 id=\"2-参数介绍：\"><a href=\"#2-参数介绍：\" class=\"headerlink\" title=\"2 参数介绍：\"></a>2 参数介绍：</h3><p>binarySplits  是否使用二进制分裂名词性属性；默认False<br>confidenceFactor  用于修剪的置信因子（小于该值导致修剪）；默认0.25<br>debug  设置为true，则分类器可能在控制台输出另外的信息；默认False<br>minNumObj  每个叶的最小实例数量；默认2<br>numFolds 决定用于reduced-error（减少-误差）修剪的数据量；一折用于修剪，另外的用于建树；默认3<br>reducedErrorPruning  是否使用减少-误差修剪，而不是C4.5修剪；默认：False<br>saveInstanceData  是否为了展示保存训练数据；默认：False<br>seed  减少-误差修剪时，用于随机化数据的种子；默认：1<br>subtreeRaising  修剪树的时候是否考虑子树上升操作；默认：True<br>unpruned  修剪是否需要；默认：False<br>useLaplace  是否叶节点基于拉普拉斯平滑；默认：False<br>修剪的方式：存在C.4.5修剪，和减少-误差修剪；reducedErrorPruning控制，默认是C.4.5修剪；<br>是否修剪：unpruned控制，默认是修剪；<br>如果没有专门设置检验数据集，为了保证生成的模型的准确性而不至于出现过拟合（overfitting）的现象，有必要采用交叉验证（一般选择10-fold cross validation）来选择和评估模型。 </p>\n<p>右键点击“Results list”中项，弹出菜单中选择“Visualize tree”，新窗口里可以看到图形模式的决策树。建议把这个新窗口最大化，然后点右键，选“Fit to screen”，可以把这个树看清楚些。<br>解释一下“Confusion Matrix”的含义：<br>=== Confusion Matrix ===<br>  a b &lt;– classified as<br>  741 24 | a = YES<br>  10 582 | b = NO<br>这个矩阵是说，原本“pep”是“YES”的实例，有741个被正确的预测为 “YES”，有24个错误的预测成了“NO”；原本“pep”是“NO”的实例，有10个被错误的预测为“YES”，有582个正确的预测成了“NO”。 741+24+10+582 = 1375是实例总数，而(741+582)/1375 = 0.96218正好是正确分类的实例所占比例。</p>\n<p>我们要用生成的模型对那些待预测的数据集进行预测了，注意待预测数据集和训练用数据集各个属性的设 置必须是一致的。WEKA中并没有直接提供把模型应用到带预测数据集上的方法，我们要采取间接的办法。<br>在“Test Opion”中选择“Supplied test set”，并且“Set”成要验证的文件，“Start”一次。<br>右键点击“Result list”中刚产生的那一项，选择“Visualize classifier errors”。点“Save”按钮，将结果保存。这个ARFF文件中就有我们需要的预测结果。在“Explorer”的“Preprocess”选项卡中打开这个新文件，可以看到多了两个属性 “Instance_number”和“predictedpep”。“Instance_number”是指一个实例在原文件中的位置，“predictedpep”就是模型预测的结果。点“Edit”按钮或者在“ArffViewer”模块中打开可以查 看这个数据集的内容。<br><img src=\"http://upload-images.jianshu.io/upload_images/11634944-884f92b05f6e921c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600\" alt=\"这是一张图\"></p>\n","text":"1 简介WEKA把分类(Classification)和回归(Regression)都放在“Classify”选项卡中，我们希望根据一个样本的一组特征，对目标进行预测。为了实现这一目的， 我们需要有一个训练数据集，这个数据集中每个实例的输入和输出都是已知的。观察训练集中的实例，可","link":"","raw":null,"photos":[],"categories":[{"name":"数学建模","slug":"数学建模","count":2,"path":"api/categories/数学建模.json"}],"tags":[{"name":"WEKA","slug":"WEKA","count":1,"path":"api/tags/WEKA.json"},{"name":"分类与回归","slug":"分类与回归","count":1,"path":"api/tags/分类与回归.json"}]}]}